{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalNaiveBayes:\n",
    "    def get_distrebutions_for_features(self, X, y):\n",
    "        dataset = np.column_stack((X, y))\n",
    "        data_per_classes = {}\n",
    "        for row in dataset:\n",
    "            class_k = row[-1]\n",
    "            if class_k in data_per_classes.keys():\n",
    "                data_per_classes[class_k].append(row[0:-1])\n",
    "            else:\n",
    "                data_per_classes[class_k] = list([row[0:-1]])\n",
    "\n",
    "        self.p_classes = {class_data:len(data_per_classes[class_data])/len(X) for class_data in data_per_classes.keys()}\n",
    "\n",
    "        features_distribs = {}\n",
    "        for class_k in data_per_classes.keys():\n",
    "            data = pd.DataFrame(data_per_classes[class_k])\n",
    "            var = data.std(ddof=1)\n",
    "            mean = data.mean()\n",
    "            var_mean_dataframe = pd.DataFrame([var, mean])\n",
    "            features_distribs[class_k] = dict()\n",
    "            for column in var_mean_dataframe.columns:\n",
    "                params = var_mean_dataframe[column].tolist()\n",
    "                features_distribs[class_k][column] = st.norm(params[1], params[0])\n",
    "\n",
    "        self.features_distribs = features_distribs\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        prob_per_class_for_x = list()\n",
    "        for x in X:\n",
    "            evidence = 0\n",
    "            probs = list()\n",
    "            for class_k in self.features_distribs:\n",
    "                posterior_denumerator_k = self.p_classes[class_k]\n",
    "                distribs = self.features_distribs[class_k]\n",
    "                for distrubs_key in distribs.keys():\n",
    "                    posterior_denumerator_k *= distribs[distrubs_key].pdf(x[distrubs_key])\n",
    "                probs.append(posterior_denumerator_k)\n",
    "                evidence += posterior_denumerator_k\n",
    "            prob_per_class_for_x.append(np.array(probs) / evidence)\n",
    "        return prob_per_class_for_x\n",
    "    \n",
    "    def predict_class(self, X):\n",
    "        probs = self.predict_prob(X)\n",
    "        predict = list()\n",
    "        class_labels = list(self.p_classes.keys())\n",
    "        for prob in probs:\n",
    "            predict.append(class_labels[prob.argmax()])\n",
    "        return np.array(predict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NormalNaiveBayes()\n",
    "model.get_distrebutions_for_features(X_train, y_train)\n",
    "predict = model.predict_class(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(y_test == predict)/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1., 0., 2., 0., 2., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 2., 1., 0., 0., 2., 0., 0., 1., 1., 0., 2., 1., 0., 2.,\n",
       "        2., 1., 0., 1., 1., 1., 2., 0., 2., 0., 0., 1., 2., 2., 1., 2., 1.,\n",
       "        2., 1., 1., 2., 1., 1., 2., 1., 2., 1., 0., 2., 1., 1., 1., 1., 2.,\n",
       "        0., 0., 2., 1., 0., 0., 1.]),\n",
       " array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "        0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0,\n",
       "        0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "        1, 2, 0, 0, 2, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
