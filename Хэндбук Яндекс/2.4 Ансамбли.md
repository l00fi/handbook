#машинное_обучение #хэндбук 

[Хэндбук](https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii)

Ансамбль - это объединение нескольких моделей каким-либо методом в одну, с целью улучшения предсказаний таргета целевого объекта. ^77b424

# Смещение и разброс

Предположим существует какая-то функция  $Q(a)$ (**для каждой функции она своя**), оценивающая работу алгоритма $a(x, X)$ (то есть предсказание модели, обученной на выборке $X$, по объекту $x$).

Для средней квадратичной ошибки:$$Q(a)=\mathbb{E}_{x}\mathbb{E}_{X,\epsilon}[y(x, \epsilon)-a(x, X)]$$
$Q(a)$ можно представить как:$$Q(a)=\mathbb{E}_{x}bias_{x}^{2}a(x, X) + \mathbb{E}_{x}\mathbb{V}_{X}[a(x, X)] + \sigma^{2}$$
1. $\sigma^{2}$ - неустранимый шум.
2. $bias_{x}^{2}a(x, X)=f(x)-\mathbb{E}_{X}[a(x, X)]$ - смещение предсказания алгоритма, усредненного по всем возможным обучающим выборкам. 

Шум, так как он не устраним, нельзя никак уменьшить, зато можно уменьшить **дисперсию (разброс)** или **смещение**.

# Бэггинг (bagging)

Алгоритм:
1. Из выборки $X$, чьи объекты распределены равновероятно, сформируем, с возвращением, обучающую выборку $X^{1}$. Данный процесс называется **boostrap**.
2. Обучим модель $b_{1}(x, X^{1})$ на сформированной выборке. 
3. Повторим $k$ раз описанные выше два пункта.
4. Итоговое предсказание модели равно:$$a(x)=\frac{1}{k}(b_{1}(x) + b_{2}(x) + ... + b_{k}(x))$$
$a(x)$ и есть [[2.4 Ансамбли#^77b424|ансамбль]].

В итоге, предполагая что корреляция между признаками отсутствует, получаем уменьшение дисперсии в $k$ раз. Доказательство это смотри в хэндбуке.

# Random forest

Это развитие бэггинга для [[2.3 Решающие деревья|решающих деревьев]], говоря более подробно - **комбинация случайных подпространств и бэггинга**.

Пусть $b(x)$ (базовый алгоритм) - это решающее дерево. Тогда алгоритм следующий:
1. Шаг аналогичен формированию обучающей выборки $X^{1}$ для бэггинга.
2. Для каждого дерева для каждой вершины случайно выбирается $n<N$ (где $N$ - число признаков в обучающей выборке) признаков. Это и есть случайные подпространства.
3. Ответ ансамбля есть **среднее ответов** ([[2.1 Линейные модели#Линейная регрессия и МНК|регрессия]]), либо **самый популярный класс** ([[2.1 Линейные модели#Логистическая регрессия|классификация]]) 

Важные моменты:
1. Используем глубокие деревья, так как они имеют низкое смещение.
2. Для регрессии количество признаков на обучение отдельного дерева равно **трети от всех признаков обучающей выборки**, для классификации - **корень**.
3. Размер леса увеличиваем до момента пока ошибка значительно изменяется.
4. Ограничить время обучения леса (даже если процесс обучения каждого дерева можно распараллелить).

# Бустинг

Ансамблевый метод, где модели учатся последовательно, учитывая ошибки предыдущих, в следствии чего **уменьшается смещение**, но **уменьшение дисперсии не гарантировано**.

Для бустинга используются модели с высоким смещением и небольшой дисперсией.

# Стекинг (stacking)

Особенности:
1. Модели $b(x)$ не ограничиваются одним семейством, то есть в рамках одного ансамбля могут иметь место, например, линейная регрессия и [[2.2 Метрические методы#Метод k-ближайших соседей (KNN)|k-ближайших соседей ]].
2. Все модели объединяются одной мета-моделью.

Алгоритм:
1. Обучающая выборка делится на $n$ фолды (fold) - не пересекающихся подмножеств множества $X$. ИЗ них $(n-1)$ будут применяться для обучения моделей, а оставшаяся для предсказаний. Предсказания моделей называются **мета-фактор**.
2. На мета-факторах и признаках из обучающей выборки (опционально) обучается та самая **мета-модель**.