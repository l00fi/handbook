#хэндбук #машинное_обучение 

[Хэндбук](https://education.yandex.ru/handbook/ml/article/kross-validaciya)

**Кросс-валидация** - это процедура оценки качества работы модели.
# Виды кросс-валидации
## Hold-out
Это простое разделение данных на трейн и тест.

**Важно! Перед разделением нужно перемешать данные.**
```
Это нужно, чтобы избежать ситуаций, когда, например, первые 500 фотографий датасета содержит только фото собак, а вторая половина содержит только фото котов. Если не перемешать данные, то модель обучиться определять на фото собак, но никак не отличать их от кошек.
```

Если у нас достаточно много данных, то нужно кроме трейн и теста выделить также **валидационное множество**, на котором будет происходить настройка гиперпараметров или архитектуры нейросети.
```
Это делается для того, чтобы через гипрпараметры не дать модели узнать какую-то информацию о тестовой выборке
```

На финальном этапе, когда вид модели и её гиперпараметры настроены, ндао обучить её на всем датасете, а не только на трейне - чтобы было больше исходных данных, очевидно.

Чтобы оставить возможность как-то оценить качество модели, можно построить **график кривой обучения** - по оси Y - Score, по оси X - количество объектов на которых обучена модель, а сами кривые есть результаты модели на данных в трейне и тесте. Если кривые сходятся, то, скорее всего, улучшить её уже на вряд ли выйдет, в противном случае надежда есть. и в трейн можно добавить ещё данных.

### Стратификация
Это разумный подход к разбиению даты на тест и трейн, который учитывает ситуацию **неравномерности классов в подвыборках**
```
То есть, если во всём датасете классов трех видов примерно 33%, то, при случайном разбиении на трейн и тест эта ситуация может измениться и в данных, на которых модель обучается баланс классов может быть нарушен
```

## K-Fold
Является обобщением hold-out. Алгоритм следующий:
1. Фиксируется некоторое целое число $k$ (обычно от 5 до 10), меньшее числа семплов в датасете.
2. Датасет разбивается на $k$ одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются _фолдами_.
3. Далее происходит $k$ итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на $k−1$ фолде и тестируется на оставшемся.
4. Финальный скор модели получается либо усреднением $k$ получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.

## Leave-on-out
Частный случай k-fold, где каждый фолд состоит из одного объекта.

# Когда стоит задуматься о том, что оценка завышена

1. Данные не перемешивались;
2. На тестовом множестве приходится корректировать гиперпараметры;
3. В данных имеется фича очень похожая на таргет;
4. Feature engineering проведен на всем датасете, а не только на трейне;
5. Весь датасет стандартизирован, а не только трейн;
6. Смешан трейн с тестом.