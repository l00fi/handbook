#хэндбук #машинное_обучение 

[Хэндбук](https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml)

# Случайность как источник несовершенства модели
Можно рассматривать построение **линейной регрессии** следующим образом: $$y \approx \langle{x, w}\rangle$$
Так как при расчёте таргета нельзя учесть абсолютно все факторы, влияющие на него, потому что некоторые из них могут быть не известны. 

Поэтому задачу можно интерпретировать по другому: $$y = \langle{x, w} \rangle + \epsilon$$
Не строгое равенство можно заменить строгим как как $\epsilon$ является **шумом** - всеми неизвестными параметрами, которые влияют на таргет. Этот шум является случайной величиной потому что мы ничего о нем не знаем, и исходя из этого, достаточно часто он является **гауссовым распределением** $\epsilon \sim N(0, \sigma^{2})$ где $\sigma$ какое-то стандартное отклонение которые мы и хотим выяснить.

Следовательно каждый $x_{i}$ имеет степень свободы -  он определен не однозначно из-за **случайного** шума.

# Условное распределение на таргет, непрерывный случай

$$y \sim p_{y}(y|x, w)$$
Это есть условное распределение таргета, зависящего от параметров $x$ и $w$. В изначальном выражении функция $f_{w}(x_{i})$ является константой, но так как имеется случайный шум $\epsilon \sim N(0, \sigma^{2})$, то в каждом конкретном случае получается следующее: $$y_{i} \sim N(\langle{x, w} \rangle, \sigma^{2})$$
Это можно сделать, так как сумма **константы и нормально распределенной случайной величины есть нормальная случайная величина.** 

Мысль можно развить дальше и записать: $$p(y_{i}|x_{i}, w)\sim N(y_{i}|\langle{x_{i}, w}\rangle, \sigma^{2})$$ 

**Важно!**
$$p(y_{i}|x_{i}, w) = p_{\epsilon}(y - f_{w}(x_{i}))$$

# Оценка функции правдоподобия = оптимизация функции потерь

Суть метода максимального правдоподобия сводится к **нахождению таких $w$, что вероятность появление выборки $y = \{y_{1},...,y_{n}\}$ была максимальна**: $$\hat{w}_{MLE}=arg\max_{w}(p(y|X, w))$$
Функция которую мы максимизируем есть **функция правдоподобия**:
$$p(y|X, w)$$
Далее, для её максимизации **возьмем логарифм**, так как, при независимости каждого наблюдения, общая вероятность распадается на произведение вероятностей каждого отдельного наблюдения, и их всё-таки хочется складывать потому что в дальнейшем придется находить производную получившегося выражения, то есть:$$l(y|X, w)=\sum\limits_{i=1}^{N}log(p(y_{i}|x_{i}, w))=\sum\limits_{i=1}^{N}log(p_{\epsilon}(y - f_{w}(x_{i})))$$
Если вместо максимизации выполнить аналогичную задачу наоборот, минимизируя, то:$$\sum\limits_{i=1}^{N}-log(p_{\epsilon}(y - f_{w}(x_{i})))$$
**А это выражение можно интерпретировать как функцию потерь!** 
То есть чем ближе разность $y - f_{w}(x_{i})$ к реальному значению $\epsilon$ тем больше вероятность и, соответственно, тем меньше логарифм вероятности. В идеале хочется получить ноль, но так навряд-ли получится. 

Кратко напишу, что **предсказания** вероятностной модели есть математическое ожидание $\mathbb{E}(y|x)$.